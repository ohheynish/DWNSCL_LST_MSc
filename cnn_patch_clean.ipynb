{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f8da3e-0131-4123-928f-ba318bd6d9e0",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "\n",
    "import ee\n",
    "from osgeo import gdal\n",
    "from osgeo import gdalconst\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from scipy import ndimage\n",
    "from scipy.stats import linregress\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7e3cdb-a51e-44eb-90d0-9c7e405218b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the ee api through credentials\n",
    "\n",
    "# ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0219317-8896-4e2c-8182-85db22f67975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load study area\n",
    "\n",
    "fc = ee.FeatureCollection(\"FAO/GAUL_SIMPLIFIED_500m/2015/level1\")\n",
    "roi = fc.filter(ee.Filter.eq('ADM1_NAME', 'Zuid-holland'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e08b5d1-1675-4e01-a2cc-c7ea3f93cd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer images from ee to numpy array (for intersecting dates)\n",
    "sentinel_dates = ['2020-03-25']\n",
    "sar_arrs = []\n",
    "\n",
    "for dates in sentinel_dates:\n",
    "    sentinel = ee.ImageCollection('COPERNICUS/S1_GRD')\n",
    "    asc = sentinel.filter(ee.Filter.eq('orbitProperties_pass', 'ASCENDING')).filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
    "    platform = asc.filter(ee.Filter.eq('platform_number', 'A'))\n",
    "    coll_param = platform.filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH')).select(['VV', 'VH'])\n",
    "\n",
    "    sentinel_roi = coll_param.filterBounds(roi.geometry())\n",
    "\n",
    "    bcoff = sentinel_roi.filterDate(dates, '2021-01-01').first()\n",
    "\n",
    "    bcoff_new = bcoff.reduceResolution(reducer=ee.Reducer.median(), maxPixels=1e4).reproject(crs='EPSG:4326', scale=1000)\n",
    "\n",
    "    sar_arr = bcoff_new.sampleRectangle(region=roi.geometry(), defaultValue=-9999)\n",
    "\n",
    "    sar_arr_VV = sar_arr.get('VV')\n",
    "    sar_arr_VH = sar_arr.get('VH')\n",
    "\n",
    "    npsar_arr_VV = np.array(sar_arr_VV.getInfo())\n",
    "    sar_arrs.append(npsar_arr_VV)\n",
    "    npsar_arr_VH = np.array(sar_arr_VH.getInfo())\n",
    "    sar_arrs.append(npsar_arr_VH)\n",
    "\n",
    "    print(npsar_arr_VV.shape)\n",
    "    print(npsar_arr_VH.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbad5d3c-2d8e-4a78-b3a1-0dad72fc0d9b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# prepare arrays for plotting\n",
    "\n",
    "vv_arr = sar_arrs[0]\n",
    "print('The shape of the vv_backscatter array is:', vv_arr.shape)\n",
    "print()\n",
    "\n",
    "vh_arr = sar_arrs[1]\n",
    "print('The shape of the vv_backscatter array is:', vv_arr.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92491c0-32e1-46ef-8c18-0d3d6c8e4d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data for extent correction\n",
    "\n",
    "extent_data = gdal.Open('data/modisval_2905.tif')\n",
    "geoTransform = extent_data.GetGeoTransform()\n",
    "ulx = geoTransform[0]\n",
    "uly = geoTransform[3]\n",
    "lrx = ulx + geoTransform[1] * extent_data.RasterXSize\n",
    "lry = uly + geoTransform[5] * extent_data.RasterYSize\n",
    "print(ulx, uly, lrx, lry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06049107-a5b8-4e6e-b10d-dfe5d66add30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get landsat validation data and cut by extent\n",
    "\n",
    "lst_full = gdal.Open('data/l8/landsatval_2503_100.tif')\n",
    "tmp_data = gdal.Translate('/vsimem/in_memory_output.tif', lst_full, projWin=[ulx, uly, lrx, lry],\n",
    "                          outputType=gdalconst.GDT_Float32, noData=np.nan)\n",
    "lst_full_arr = tmp_data.ReadAsArray()\n",
    "lst_full_arr = lst_full_arr*0.00341802+149.0\n",
    "lst_full_farr = ndimage.median_filter(lst_full_arr, 3)\n",
    "print(lst_full_farr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceffa686-452f-4421-8b63-d187f7a203b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save lst 1000 m\n",
    "\n",
    "l8_1000 = lst_full_farr.reshape(-1, 10, 131, 10)\n",
    "l8_1000_m = np.median(l8_1000, (-1, -3))\n",
    "lst_arr = l8_1000_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73668c98",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "figure(figsize=(14, 12), dpi=300)\n",
    "plt.imshow(lst_arr, cmap='RdBu_r')\n",
    "plt.colorbar(orientation='horizontal')\n",
    "plt.title('LST image over Zuid-Holland (1000 m)', y=-0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ede95aa",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "figure(figsize=(14, 12), dpi=300)\n",
    "plt.imshow(vv_arr, cmap='Greys_r')\n",
    "plt.colorbar(orientation='horizontal')\n",
    "plt.title('VV image over Zuid-Holland (1000 m)', y=-0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8224b4f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 20))\n",
    "\n",
    "img_1 = ax[0].imshow(lst_arr, cmap='RdBu_r')\n",
    "fig.colorbar(img_1, ax=ax[0], orientation='horizontal')\n",
    "ax[0].set_title('LST image over Zuid-Holland (1000 m)', y=-0.5)\n",
    "\n",
    "img_2 = ax[1].imshow(vv_arr, cmap='Greys_r')\n",
    "fig.colorbar(img_2, ax=ax[1], orientation='horizontal')\n",
    "ax[1].set_title('VV image over Zuid-Holland (1000 m)', y=-0.5)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db68e165-9a75-4331-8215-81b5cc249723",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## SAR feature processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9611de4f-2c29-4b40-8179-e82af380a89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sar data and cut it by modis extent\n",
    "\n",
    "sar_full = gdal.Open('data/s1/sarval_2503_vv_vh.tif')\n",
    "tmp_data_sar = gdal.Translate('/vsimem/in_memory_output.tif', sar_full, projWin=[ulx, uly, lrx, lry],\n",
    "                              outputType=gdalconst.GDT_Float32, noData=np.nan)\n",
    "vv_full_arr = tmp_data_sar.ReadAsArray()[0]\n",
    "vv_full_farr = ndimage.median_filter(vv_full_arr, 3)\n",
    "print(vv_full_farr.shape)\n",
    "\n",
    "vh_full_arr = tmp_data_sar.ReadAsArray()[1]\n",
    "vh_full_farr = ndimage.median_filter(vh_full_arr, 3)\n",
    "print(vh_full_farr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22f8d64-b528-4d4d-9c8f-528b6d2b0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upscale to 100 m res\n",
    "\n",
    "n_vv_full_arr = vv_full_farr.reshape(-1, 10, 1310, 10)\n",
    "m_vv_full_arr = np.median(n_vv_full_arr, (-1, -3))\n",
    "print(m_vv_full_arr.shape)\n",
    "print(m_vv_full_arr)\n",
    "\n",
    "# upscale to 100 m res\n",
    "\n",
    "n_vh_full_arr = vh_full_farr.reshape(-1, 10, 1310, 10)\n",
    "m_vh_full_arr = np.median(n_vh_full_arr, (-1, -3))\n",
    "print(m_vh_full_arr.shape)\n",
    "print(m_vh_full_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26982c8-cabb-47e5-aaf8-7aede95da949",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(14, 12), dpi=300)\n",
    "plt.imshow(m_vh_full_arr, cmap='RdBu_r')\n",
    "plt.colorbar(orientation='horizontal')\n",
    "plt.title('VV image over Zuid-Holland (100 m)', y=-0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182526bb-0d6e-4c29-b5bc-25cd97bb67f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Scale and remove nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbf27a4-8bd1-411d-b167-f9a69b56aa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove nan\n",
    "vv_arr[np.isnan(vv_arr)] = np.nanmean(vv_arr)\n",
    "m_vv_full_arr[np.isnan(m_vv_full_arr)] = np.nanmean(m_vv_full_arr)\n",
    "vv_full_farr[np.isnan(vv_full_farr)] = np.nanmean(vv_full_farr)\n",
    "\n",
    "vh_arr[np.isnan(vh_arr)] = np.nanmean(vh_arr)\n",
    "m_vh_full_arr[np.isnan(m_vh_full_arr)] = np.nanmean(m_vh_full_arr)\n",
    "vh_full_farr[np.isnan(vh_full_farr)] = np.nanmean(vh_full_farr)\n",
    "\n",
    "# scale\n",
    "vv_arr_norm = (vv_arr - np.nanmin(vv_arr))/(np.nanmax(vv_arr) - np.nanmin(vv_arr))\n",
    "m_vv_full_arr_norm = (m_vv_full_arr - np.nanmin(m_vv_full_arr))/(np.nanmax(m_vv_full_arr) - np.nanmin(m_vv_full_arr))\n",
    "vv_full_farr_norm = (vv_full_farr - np.nanmin(vv_full_farr))/(np.nanmax(vv_full_farr) - np.nanmin(vv_full_farr))\n",
    "\n",
    "vh_arr_norm = (vh_arr - np.nanmin(vh_arr))/(np.nanmax(vh_arr) - np.nanmin(vh_arr))\n",
    "m_vh_full_arr_norm = (m_vh_full_arr - np.nanmin(m_vh_full_arr))/(np.nanmax(m_vh_full_arr) - np.nanmin(m_vh_full_arr))\n",
    "vh_full_farr_norm = (vh_full_farr - np.nanmin(vh_full_farr))/(np.nanmax(vh_full_farr) - np.nanmin(vh_full_farr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a16605-751a-4780-a071-1874a5cb6d03",
   "metadata": {},
   "source": [
    "/for reg,\n",
    "vv_arr = vv_arr at 1000 m,\n",
    "m_vv_full_arr = vv_arr at 100 m\n",
    "\n",
    "/for cnn,\n",
    "vv_patches = (10, 10) patches from 100 m vv image,\n",
    "vv_patches_100 = (10, 10) patches from 10 m vv image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55168f74-da74-46bb-aef0-dbf819779f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patches\n",
    "\n",
    "vv_patches = [m_vv_full_arr_norm[x:x+10, y:y+10].reshape(10, 10, 1) for x in range(0, m_vv_full_arr_norm.shape[0], 10) for y in range(0, m_vv_full_arr_norm.shape[1], 10)]\n",
    "with tf.device('cpu:0'):\n",
    "    vv_patches_tensor = tf.convert_to_tensor(vv_patches)\n",
    "print(vv_patches_tensor.shape)\n",
    "\n",
    "vh_patches = [m_vh_full_arr_norm[x:x+10, y:y+10].reshape(10, 10, 1) for x in range(0, m_vh_full_arr_norm.shape[0], 10) for y in range(0, m_vh_full_arr_norm.shape[1], 10)]\n",
    "with tf.device('cpu:0'):\n",
    "    vh_patches_tensor = tf.convert_to_tensor(vh_patches)\n",
    "print(vh_patches_tensor.shape)\n",
    "\n",
    "vv_patches_100 = [vv_full_farr_norm[x:x+10, y:y+10].reshape(10, 10, 1) for x in range(0, vv_full_farr_norm.shape[0], 10) for y in range(0, vv_full_farr_norm.shape[1], 10)]\n",
    "with tf.device('cpu:0'):\n",
    "    vv_patches_tensor_100 = tf.convert_to_tensor(vv_patches_100)\n",
    "print(vv_patches_tensor_100.shape)\n",
    "\n",
    "vh_patches_100 = [vh_full_farr_norm[x:x+10, y:y+10].reshape(10, 10, 1) for x in range(0, vh_full_farr_norm.shape[0], 10) for y in range(0, vh_full_farr_norm.shape[1], 10)]\n",
    "with tf.device('cpu:0'):\n",
    "    vh_patches_tensor_100 = tf.convert_to_tensor(vh_patches_100)\n",
    "print(vh_patches_tensor_100.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04f0af4-edc7-4a56-af88-182d0580bd70",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## S2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829cadfe-218a-44f2-807e-04d3f7f3ab25",
   "metadata": {},
   "source": [
    "### uncomment the below code to use patches from sentinel-2 data as input to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca3aa21-fe26-4694-b1a7-d2d0e015250c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # s2 1000 m product\n",
    "\n",
    "# s2_arrs = []\n",
    "\n",
    "# s2_data = gdal.Open('data/s2/s2_2603_1000.tif')\n",
    "\n",
    "# for i in range(s2_data.RasterCount):\n",
    "#     s2_arrs.append(s2_data.ReadAsArray()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d3912b-5ba9-4e66-8775-839b8ad934b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get s2 data and cut it by extent\n",
    "\n",
    "# s2_full_arrs = []\n",
    "\n",
    "# s2_full = gdal.Open('data/s2/s2_2603_10.tif')\n",
    "# tmp_data_s2 = gdal.Translate('/vsimem/in_memory_output.tif', s2_full, projWin=[ulx, uly, lrx, lry],\n",
    "#                               outputType=gdalconst.GDT_Float32, noData=np.nan)\n",
    "\n",
    "# for i in range(tmp_data_s2.RasterCount):\n",
    "#     arr = ndimage.median_filter(tmp_data_s2.ReadAsArray()[i], 3)\n",
    "#     s2_full_arrs.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc4d144-4c59-438b-8326-ee360c7f02ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # upscale to 100 m res\n",
    "\n",
    "# s2_full_arrs_100 = []\n",
    "\n",
    "# for arr in s2_full_arrs:\n",
    "#     n_arr = arr.reshape(-1, 10, 1310, 10)\n",
    "#     m_n_arr = np.median(n_arr, (-1, -3))\n",
    "#     s2_full_arrs_100.append(m_n_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a7ebb8-7824-4c4a-8b42-9500c72e2e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(s2_arrs), len(s2_full_arrs), len(s2_full_arrs_100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f905e6-a0b8-4036-961e-dd987522a812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove nan and scale\n",
    "# s2_arrs_norm = []\n",
    "# for arr in s2_arrs:\n",
    "#     arr[np.isnan(arr)] = np.nanmean(arr)\n",
    "#     arr_norm = (arr - np.nanmin(arr))/(np.nanmax(arr) - np.nanmin(arr))\n",
    "#     s2_arrs_norm.append(arr_norm)\n",
    "\n",
    "# s2_full_arrs_norm = []\n",
    "# for arr in s2_full_arrs:\n",
    "#     arr[np.isnan(arr)] = np.nanmean(arr)\n",
    "#     arr_norm = (arr - np.nanmin(arr))/(np.nanmax(arr) - np.nanmin(arr))\n",
    "#     s2_full_arrs_norm.append(arr_norm)\n",
    "\n",
    "# s2_full_arrs_100_norm = []\n",
    "# for arr in s2_full_arrs_100:\n",
    "#     arr[np.isnan(arr)] = np.nanmean(arr)\n",
    "#     arr_norm = (arr - np.nanmin(arr))/(np.nanmax(arr) - np.nanmin(arr))\n",
    "#     s2_full_arrs_100_norm.append(arr_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e406271d-1568-49c7-ae01-17d01303d3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(s2_arrs_norm), len(s2_full_arrs_norm), len(s2_full_arrs_100_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82287d66-b831-4334-8f0f-ef7fd79880b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s2_10_patches = []\n",
    "# for arr in s2_full_arrs_norm:\n",
    "#     arr_patch = [arr[x:x+10, y:y+10].reshape(10, 10, 1) for x in range(0, arr.shape[0], 10) for y in range(0, arr.shape[1], 10)]\n",
    "#     with tf.device('cpu:0'):\n",
    "#         arr_tensor = tf.convert_to_tensor(arr_patch)\n",
    "#     s2_10_patches.append(arr_tensor)\n",
    "\n",
    "# s2_100_patches = []\n",
    "# for arr in s2_full_arrs_100_norm:\n",
    "#     arr_patch = [arr[x:x+10, y:y+10].reshape(10, 10, 1) for x in range(0, arr.shape[0], 10) for y in range(0, arr.shape[1], 10)]\n",
    "#     with tf.device('cpu:0'):\n",
    "#         arr_tensor = tf.convert_to_tensor(arr_patch)\n",
    "#     s2_100_patches.append(arr_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00d3969-9dc0-4509-b597-2f25637df6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('cpu:0'):\n",
    "#     s2_patches_tensor_10 = tf.concat(s2_10_patches, axis=-1)\n",
    "# print(s2_patches_tensor_10.shape)\n",
    "\n",
    "# with tf.device('cpu:0'):\n",
    "#     s2_patches_tensor = tf.concat(s2_100_patches, axis=-1)\n",
    "# print(s2_patches_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dcee42-ead0-4780-9b56-daaaea1ef7a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## LULC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d384207-8668-4686-8e3d-06147cae8485",
   "metadata": {},
   "outputs": [],
   "source": [
    "lulc_data = gdal.Open('data/esa_lulc_100.tif')\n",
    "tmp_data_lulc = gdal.Translate('/vsimem/in_memory_output.tif', lulc_data, projWin=[ulx, uly, lrx, lry],\n",
    "                              outputType=gdalconst.GDT_Float32, noData=np.nan)\n",
    "lulc_arr = tmp_data_lulc.ReadAsArray()\n",
    "print(lulc_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564fd031-9456-4226-a8dd-913d6534c535",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(14, 12), dpi=300)\n",
    "plt.imshow(lulc_arr)\n",
    "plt.colorbar(orientation='horizontal')\n",
    "plt.title('LULC image over Zuid-Holland (100 m)', y=-0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7aefd7-22f3-4cbf-9b12-2b2a65a928c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lulc_data_10 = gdal.Open('data/esa_lulc_10.tif')\n",
    "tmp_data_lulc = gdal.Translate('/vsimem/in_memory_output.tif', lulc_data_10, projWin=[ulx, uly, lrx, lry],\n",
    "                              outputType=gdalconst.GDT_Float32, noData=np.nan)\n",
    "lulc_arr_10 = tmp_data_lulc.ReadAsArray()\n",
    "print(lulc_arr_10.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b86273-17dd-4a3f-b6ab-d16e3827ffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove nan and normalize\n",
    "lulc_arr[np.isnan(lulc_arr)] = 80.0\n",
    "lulc_arr_10[np.isnan(lulc_arr_10)] = 80.0\n",
    "\n",
    "# normalize\n",
    "lulc_arr_norm = (lulc_arr - np.nanmin(lulc_arr))/(np.nanmax(lulc_arr) - np.nanmin(lulc_arr))\n",
    "lulc_arr_10_norm = (lulc_arr_10 - np.nanmin(lulc_arr_10))/(np.nanmax(lulc_arr_10) - np.nanmin(lulc_arr_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33bbbd5-0cc7-4221-8f01-bd75d84088a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lulc_patches = [lulc_arr_norm[x:x+10, y:y+10].reshape(10, 10, 1) for x in range(0, lulc_arr_norm.shape[0], 10) for y in range(0, lulc_arr_norm.shape[1], 10)]\n",
    "with tf.device('cpu:0'):\n",
    "    lulc_patches_tensor = tf.convert_to_tensor(lulc_patches)\n",
    "print(lulc_patches_tensor.shape)\n",
    "\n",
    "lulc_patches_100 = [lulc_arr_10_norm[x:x+10, y:y+10].reshape(10, 10, 1) for x in range(0, lulc_arr_10_norm.shape[0], 10) for y in range(0, lulc_arr_10_norm.shape[1], 10)]\n",
    "with tf.device('cpu:0'):\n",
    "    lulc_patches_tensor_100 = tf.convert_to_tensor(lulc_patches_100)\n",
    "print(lulc_patches_tensor_100.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45b4c8e-a66e-48f8-9f94-165343300e45",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## predictors and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a36b39-d775-4079-81da-786ef8b52b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack tensors cnn\n",
    "\n",
    "predictor_tensor = tf.concat([lulc_patches_tensor, vv_patches_tensor, vh_patches_tensor], axis=-1)\n",
    "# predictor_tensor = s2_patches_tensor\n",
    "print(predictor_tensor.shape)\n",
    "\n",
    "# target\n",
    "lst_arr_norm = (lst_arr - np.nanmin(lst_arr))/(np.nanmax(lst_arr) - np.nanmin(lst_arr))\n",
    "target_values = lst_arr_norm.flatten()\n",
    "target_tensor = tf.convert_to_tensor(target_values)\n",
    "print(target_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e3c1a9-e8a6-4da8-91be-296a828cb2d5",
   "metadata": {},
   "source": [
    "**Here the shape of the predictor is (num of samples, patch_size_x, patch_size_y, num of predictors). The idea is to map a (10, 10) patch at 100 m resolution predictor image to the corresponding coarse resolution pixel at 1000 m**\n",
    "\n",
    "**for prediction, (10, 10) patches are collected again but now from 10 m image to correspondingly estimate target values at 100 m**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7654674a-1642-4b7f-93ec-0148ae22edd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove nan\n",
    "\n",
    "# Find the indices of the NaN values in the target array\n",
    "nan_indices = np.isnan(target_tensor)\n",
    "\n",
    "# Remove the corresponding rows from the predictor and target arrays\n",
    "predictor_tensor = predictor_tensor[~nan_indices]\n",
    "target_tensor = target_tensor[~nan_indices]\n",
    "\n",
    "print(predictor_tensor.shape)\n",
    "print(target_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051bd51b-f12b-49a8-a262-6305fba54b5d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Building Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa72863-05f5-403a-95bf-ec1a4a8538ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "\n",
    "# cnn\n",
    "input_shape_1 = (10, 10, 3)  # patch size of predictor image\n",
    "input_1 = Input(shape=input_shape_1, name='input_1')\n",
    "\n",
    "x = Conv2D(32, (10, 10), activation='relu', padding='same')(input_1)\n",
    "x = Conv2D(32, (3, 3), strides=(1, 1), activation='relu', padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), strides=(1, 1), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (5, 5), activation='relu', padding='same')(x)\n",
    "x = Conv2D(64, (3, 3), strides=(1, 1), activation='relu', padding='same')(x)\n",
    "x = Conv2D(64, (3, 3), strides=(1, 1), activation='relu', padding='same')(x)\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(16, (3, 3),  strides=(1, 1), activation='relu', padding='same')(x)\n",
    "x = Conv2D(16, (3, 3), strides=(1, 1), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "output_1 = Dense(1)(x)\n",
    "\n",
    "model = Model(inputs=input_1, outputs=output_1)\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c697ae-da49-4ea6-bfe9-a5b3b6b1dab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385d7843-68c4-4b4c-a181-a4d21e0c66bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model viz\n",
    "\n",
    "# tf.keras.utils.plot_model(model, to_file='cnn_model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784d55b6-9718-43d4-8b2a-0e07290b6503",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('cpu:0'):\n",
    "    model.fit(predictor_tensor, target_tensor, epochs=30, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dd7236-10be-4d4b-9f2c-063976b863b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack tensors for prediction\n",
    "with tf.device(\"cpu:0\"):\n",
    "    predictor_tensor_10 = tf.concat([lulc_patches_tensor_100, vv_patches_tensor_100, vh_patches_tensor_100], axis=-1)\n",
    "    # predictor_tensor_10 = s2_patches_tensor_10\n",
    "\n",
    "print(predictor_tensor_10.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33efe9e-797e-444a-a2e9-1c0a9e697dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"cpu:0\"):\n",
    "    m_pred = model.predict(predictor_tensor_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da102fbb-10bb-436e-b849-5970fb594957",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlst_norm = m_pred.reshape(-1, 1310)\n",
    "\n",
    "# inverse scaling\n",
    "dlst = dlst_norm * (np.nanmax(lst_arr) - np.nanmin(lst_arr)) + np.nanmin(lst_arr)\n",
    "\n",
    "figure(figsize=(14, 12), dpi=150)\n",
    "plt.imshow(dlst, cmap='RdBu_r')\n",
    "plt.colorbar(orientation='horizontal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1b5f1a-ac87-41e9-b15b-8fbeb396a909",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.nanmin(dlst), np.nanmax(dlst))\n",
    "print(np.nanmin(dlst_norm), np.nanmax(dlst_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7f87ff-7c20-4788-91ef-efc4ba6db5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# residual correction\n",
    "\n",
    "fulllst_pred_1000 = dlst.reshape(-1, 10, 131, 10)\n",
    "fulllst_pred_1000 = np.median(fulllst_pred_1000, (-1, -3))\n",
    "print(fulllst_pred_1000.shape)\n",
    "\n",
    "# residuals\n",
    "\n",
    "res_1000 = lst_arr - fulllst_pred_1000\n",
    "print(res_1000.shape)\n",
    "\n",
    "res_100 = res_1000.repeat(10, 0).repeat(10, 1)\n",
    "print(res_100.shape)\n",
    "print(res_100)\n",
    "\n",
    "plt.imshow(res_1000)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fddf0c-3567-4d82-b75e-11b1dad28155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add residuals to the prediction\n",
    "\n",
    "dlst_res = dlst + res_100\n",
    "print(dlst_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056d868f-6839-486b-9533-4936d9fcad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qualitative validation\n",
    "\n",
    "min_min = np.nanmin(dlst_res)\n",
    "max_max = np.nanmax(dlst_res)\n",
    "\n",
    "figure(figsize=(14, 12), dpi=300)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(dlst_res, vmin=min_min, vmax=max_max, cmap='RdBu_r')\n",
    "plt.title('Downscaled LST map')\n",
    "plt.colorbar(orientation='horizontal')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(lst_full_farr, vmin=min_min, vmax=max_max, cmap='RdBu_r')\n",
    "plt.title('Original LST map')\n",
    "plt.colorbar(orientation='horizontal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae40bd13-d40b-4b41-aed8-c146fb188d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantitative\n",
    "\n",
    "val_df = pd.DataFrame(dlst.flatten().T, columns=['dlst'])\n",
    "val_df['dlst_res'] = dlst_res.flatten().T\n",
    "val_df['lst'] = lst_full_farr.flatten().T\n",
    "val_df['lulc'] = lulc_arr.flatten().T\n",
    "\n",
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366d65e6-cb79-48a5-96ff-2d37c011eec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove lulc = 0 class\n",
    "\n",
    "val_df.loc[val_df['lst'].isnull(), :] = np.nan\n",
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ce0ed3-a975-4a41-a95b-91dbb4a34b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist plot\n",
    "hist_df = val_df[['lst', 'dlst']]\n",
    "\n",
    "figure(figsize=(14, 12), dpi=300)\n",
    "hist_plot = hist_df.plot.hist(bins=200, legend=True, alpha=0.5)\n",
    "fig = hist_plot.get_figure()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ededc2-73eb-413a-87d6-f098439dcb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# error for each pixel\n",
    "\n",
    "error_full_arr = np.sqrt(np.square(dlst_res - lst_full_farr))\n",
    "\n",
    "figure(figsize=(14, 12), dpi=150)\n",
    "plt.title('Error at each pixel')\n",
    "plt.imshow(error_full_arr, cmap='RdYlGn_r')\n",
    "plt.colorbar(orientation='horizontal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8c409e-ab90-452c-8c8c-7c7176f58788",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data_df = val_df[['lst', 'dlst', 'dlst_res', 'lulc']]\n",
    "corr_data_df = corr_data_df.dropna()\n",
    "\n",
    "print('The correlation between Observed LST and Downscaled LST at 100m is:',\n",
    "      corr_data_df['lst'].corr(corr_data_df['dlst_res']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd60774-d281-4b5c-92eb-f566a0b7131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_before = ((corr_data_df.dlst - corr_data_df.lst) ** 2).mean() ** .5\n",
    "print('RMSE before residual correction:', rmse_before)\n",
    "rmse_after = ((corr_data_df.dlst_res - corr_data_df.lst) ** 2).mean() ** .5\n",
    "print('RMSE after residual correction:', rmse_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadbce5b-dbda-48f5-bb12-e912d590d878",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope, intercept, r_value, p_value, std_err = linregress(corr_data_df['lst'], corr_data_df['dlst_res'])\n",
    "r_squared = r_value ** 2\n",
    "\n",
    "print('R^2:', r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53614ad6-7626-4e13-9fff-d78b8f0810de",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data_df_full = pd.DataFrame(data=None, columns=corr_data_df.columns, index=val_df.index)\n",
    "corr_data_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b68019-60ac-479b-a827-72328c043346",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data_df_full = corr_data_df_full.combine_first(corr_data_df)\n",
    "corr_data_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def5598e-48d7-43a7-88c8-6cdffd6c1e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_tif(img_name, src_arr, mask_img):\n",
    "    mask_data = gdal.Open(mask_img)\n",
    "    driverTiff = gdal.GetDriverByName('GTiff')\n",
    "    clfds = driverTiff.Create(img_name,\n",
    "                              mask_data.RasterXSize, mask_data.RasterYSize,\n",
    "                              1, gdal.GDT_Float32)\n",
    "    clfds.SetGeoTransform(mask_data.GetGeoTransform())\n",
    "    clfds.SetProjection(mask_data.GetProjection())\n",
    "    clfds.GetRasterBand(1).SetNoDataValue(-9999.0)\n",
    "    clfds.GetRasterBand(1).WriteArray(src_arr)\n",
    "    clfds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bc1a41-b518-4e1f-b8ce-a0ef999f8d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlst_n = corr_data_df_full.dlst.values.reshape(-1, 1310)\n",
    "dlst_n_res = corr_data_df_full.dlst_res.values.reshape(-1, 1310)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db50513-7fcb-4416-a873-7720ac32ed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_as_tif('dlst_res.tif', dlst_n_res, 'data/saving_mask_100.tif')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
