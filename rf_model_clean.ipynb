{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f8da3e-0131-4123-928f-ba318bd6d9e0",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "\n",
    "import ee\n",
    "from osgeo import gdal\n",
    "from osgeo import gdalconst\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from scipy import ndimage\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import linregress\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fc28dc-a615-4dc3-bb2c-7b1d410416b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## get sentinel-1 1000 m data from ee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d746a3c4-1f31-4146-8d5b-0588bf55c292",
   "metadata": {},
   "source": [
    "here, to get 1000 m Sentinel-1 GRD SAR image, we can directly use the ee api to transfer data from ee server to python arrays. This is possible because the transfer data size is relatively small. For instance, transferring Sentinel-1 image at original 10 m resolution is not possible due to data transfer limits set by ee. In this scenario, one can transfer the .tif files to google drive. For this refer to 'data_collection.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7e3cdb-a51e-44eb-90d0-9c7e405218b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the ee api through your credentials\n",
    "\n",
    "# ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0219317-8896-4e2c-8182-85db22f67975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load study area using feature collection\n",
    "\n",
    "fc = ee.FeatureCollection(\"FAO/GAUL_SIMPLIFIED_500m/2015/level1\")\n",
    "roi = fc.filter(ee.Filter.eq('ADM1_NAME', 'Zuid-holland'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e08b5d1-1675-4e01-a2cc-c7ea3f93cd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer images from ee to numpy array (for intersecting dates)\n",
    "\n",
    "sentinel_dates = ['2020-03-25']\n",
    "sar_arrs = []\n",
    "\n",
    "for dates in sentinel_dates:\n",
    "    sentinel = ee.ImageCollection('COPERNICUS/S1_GRD')\n",
    "    asc = sentinel.filter(ee.Filter.eq('orbitProperties_pass', 'ASCENDING')).filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
    "    platform = asc.filter(ee.Filter.eq('platform_number', 'A'))\n",
    "    coll_param = platform.filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH')).select(['VV', 'VH'])\n",
    "\n",
    "    sentinel_roi = coll_param.filterBounds(roi.geometry())\n",
    "\n",
    "    bcoff = sentinel_roi.filterDate(dates, '2021-01-01').first()\n",
    "\n",
    "    bcoff_new = bcoff.reduceResolution(reducer=ee.Reducer.median(), maxPixels=1e4).reproject(crs='EPSG:4326', scale=1000)\n",
    "\n",
    "    sar_arr = bcoff_new.sampleRectangle(region=roi.geometry(), defaultValue=-9999)\n",
    "\n",
    "    sar_arr_VV = sar_arr.get('VV')\n",
    "    sar_arr_VH = sar_arr.get('VH')\n",
    "\n",
    "    npsar_arr_VV = np.array(sar_arr_VV.getInfo())\n",
    "    sar_arrs.append(npsar_arr_VV)\n",
    "    npsar_arr_VH = np.array(sar_arr_VH.getInfo())\n",
    "    sar_arrs.append(npsar_arr_VH)\n",
    "\n",
    "    print(npsar_arr_VV.shape)\n",
    "    print(npsar_arr_VH.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0114f243-f4b7-4a5c-be97-4403d80f08a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vv_arr = sar_arrs[0]\n",
    "vh_arr = sar_arrs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03968e92-c5c3-4f03-981e-a3eedfe8986e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## LST 1000 m data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f25568-a87b-4930-bbe9-a2971b10188f",
   "metadata": {},
   "source": [
    "the images collected at different spatial resolutions could have a mismatch in number of pixels due to the border pixels not being included. For instance, a 1000 m image that has shape of (70, 131) should have the shape of (700, 1310) at 100 m resolution. This might not always be the case. Thus, we need some extent correction# get data for extent correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64696d0-b166-4499-b8ce-0904f955f46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data for extent correction\n",
    "\n",
    "extent_data = gdal.Open('data/modisval_2905.tif')\n",
    "geoTransform = extent_data.GetGeoTransform()\n",
    "ulx = geoTransform[0]\n",
    "uly = geoTransform[3]\n",
    "lrx = ulx + geoTransform[1] * extent_data.RasterXSize\n",
    "lry = uly + geoTransform[5] * extent_data.RasterYSize\n",
    "print(ulx, uly, lrx, lry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8708f3b8-c91c-441b-8444-e91b48320c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get landsat validation data and cut by modis extent\n",
    "\n",
    "lst_full = gdal.Open('data/l8/landsatval_2503_100.tif')\n",
    "tmp_data = gdal.Translate('/vsimem/in_memory_output.tif', lst_full, projWin=[ulx, uly, lrx, lry],\n",
    "                          outputType=gdalconst.GDT_Float32, noData=np.nan)\n",
    "lst_full_arr = tmp_data.ReadAsArray()\n",
    "lst_full_arr = lst_full_arr*0.00341802+149.0\n",
    "lst_full_farr = ndimage.median_filter(lst_full_arr, 3)\n",
    "print(lst_full_farr.shape)\n",
    "\n",
    "# upscale landsat lst to 1000 m\n",
    "\n",
    "new_landsat_lst = lst_full_farr.reshape(-1, 10, 131, 10)\n",
    "new_landsat_lst_arr = np.median(new_landsat_lst, (-1, -3))\n",
    "print(new_landsat_lst_arr.shape)\n",
    "print(new_landsat_lst_arr)\n",
    "\n",
    "lst_arr = new_landsat_lst_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73668c98",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "figure(figsize=(14, 12), dpi=300)\n",
    "plt.imshow(lst_arr, cmap='RdBu_r')\n",
    "plt.colorbar(orientation='horizontal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ede95aa",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "figure(figsize=(14, 12), dpi=300)\n",
    "plt.imshow(vv_arr, cmap='Greys_r')\n",
    "plt.colorbar(orientation='horizontal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8224b4f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 20))\n",
    "\n",
    "img_1 = ax[0].imshow(lst_arr, cmap='RdBu_r')\n",
    "fig.colorbar(img_1, ax=ax[0], orientation='horizontal')\n",
    "ax[0].set_title('LST image over Zuid-Holland (1000 m)', y=-0.5)\n",
    "\n",
    "img_2 = ax[1].imshow(vv_arr, cmap='Greys_r')\n",
    "fig.colorbar(img_2, ax=ax[1], orientation='horizontal')\n",
    "ax[1].set_title('VV image over Zuid-Holland (1000 m)', y=-0.5)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d16a94d-d867-405d-9a9c-cfab216627cf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5129929a-d590-432d-af56-83fa9ef1182a",
   "metadata": {},
   "source": [
    "Now that we have our basic data, let's do some data transformation and feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f551c5b-e9bd-4e7f-8b92-b922cc8e7b03",
   "metadata": {},
   "source": [
    "### Sentinel-1 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8d9a34-8861-49c7-94fc-03e83c5341ae",
   "metadata": {},
   "source": [
    "here, we have to basically generate two set of features. First is Sentinel-1 image at 1000 m resolution and 100 m resolution (1000 m image would be used to train the model and 100 m image would serve as an input for the trained model). Second is the inclusion of neighboring values. Again we do this at both 1000 m and 100 m resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9c24b5-457b-4a9e-a37c-b83328b619a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sar data and cut it by extent\n",
    "\n",
    "sar_full = gdal.Open('data/s1/sarval_2503_vv_vh.tif')\n",
    "tmp_data_sar = gdal.Translate('/vsimem/in_memory_output.tif', sar_full, projWin=[ulx, uly, lrx, lry],\n",
    "                              outputType=gdalconst.GDT_Float32, noData=np.nan)\n",
    "vv_full_arr = tmp_data_sar.ReadAsArray()[0]\n",
    "vv_full_farr = ndimage.median_filter(vv_full_arr, 3)\n",
    "print(vv_full_farr.shape)\n",
    "\n",
    "vh_full_arr = tmp_data_sar.ReadAsArray()[1]\n",
    "vh_full_farr = ndimage.median_filter(vh_full_arr, 3)\n",
    "print(vh_full_farr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd63c9f7-b0b1-4ab4-bb4d-d73c82c59f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upscale to 100 m res\n",
    "\n",
    "n_vv_full_arr = vv_full_farr.reshape(-1, 10, 1310, 10)\n",
    "m_vv_full_arr = np.median(n_vv_full_arr, (-1, -3))\n",
    "print(m_vv_full_arr.shape)\n",
    "print(m_vv_full_arr)\n",
    "\n",
    "n_vh_full_arr = vh_full_farr.reshape(-1, 10, 1310, 10)\n",
    "m_vh_full_arr = np.median(n_vh_full_arr, (-1, -3))\n",
    "print(m_vh_full_arr.shape)\n",
    "print(m_vh_full_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044dabd9-7709-4322-98b2-bf3cab8383e0",
   "metadata": {},
   "source": [
    "we now have generated the first set of features, i.e., the 1000 m and 100 m image. here, variables vv_arr and vh_arr refer to 1000 m images that would be used for training and variables m_vv_full_arr and m_vh_full_arr refer to 100 m images for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c79d84-cb5a-40f3-aefc-f98449fc3c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the neighboring values as features\n",
    "\n",
    "def test_func(values):\n",
    "    nbor_list.append(values)\n",
    "    return values.sum()\n",
    "\n",
    "\n",
    "sar = [vv_arr, vh_arr]\n",
    "fnborlist_sar_1000 = []\n",
    "\n",
    "for arrs in sar:\n",
    "    nbor_list = []\n",
    "    footprint = np.array([[1, 1, 1, 1, 1],\n",
    "                          [1, 1, 1, 1, 1],\n",
    "                          [1, 1, 0, 1, 1],\n",
    "                          [1, 1, 1, 1, 1],\n",
    "                          [1, 1, 1, 1, 1]])\n",
    "\n",
    "    results = ndimage.generic_filter(arrs, test_func, footprint=footprint)\n",
    "\n",
    "    new_nborlist = []\n",
    "    for nbor_arrays in nbor_list:\n",
    "        new_nborlist.append(nbor_arrays.reshape(-1, 1).T)\n",
    "\n",
    "    fnborlist_sar_1000.append(new_nborlist)\n",
    "\n",
    "print(len(fnborlist_sar_1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba803b61-82db-4609-baad-4da72463b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_func(values):\n",
    "    nbor_list.append(values)\n",
    "    return values.sum()\n",
    "\n",
    "\n",
    "sar = [m_vv_full_arr, m_vh_full_arr]\n",
    "fnborlist_sar_100 = []\n",
    "\n",
    "for arrs in sar:\n",
    "    nbor_list = []\n",
    "    footprint = np.array([[1, 1, 1, 1, 1],\n",
    "                          [1, 1, 1, 1, 1],\n",
    "                          [1, 1, 0, 1, 1],\n",
    "                          [1, 1, 1, 1, 1],\n",
    "                          [1, 1, 1, 1, 1]])\n",
    "\n",
    "    results = ndimage.generic_filter(arrs, test_func, footprint=footprint)\n",
    "\n",
    "    new_nborlist = []\n",
    "    for nbor_arrays in nbor_list:\n",
    "        new_nborlist.append(nbor_arrays.reshape(-1, 1).T)\n",
    "\n",
    "    fnborlist_sar_100.append(new_nborlist)\n",
    "\n",
    "print(len(fnborlist_sar_100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf6717a-74fa-41f7-b1cb-64e586c4f172",
   "metadata": {},
   "source": [
    "now we also have the neighboring values stored in lists fnborlist_sar_1000 and fnborlist_sar_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4f6d76-ee77-489c-9cbf-decd894ed6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating column names which will be useful later\n",
    "\n",
    "vv_nbr_list = []\n",
    "for i in range(1, 25):\n",
    "    vv_nbr_list.append('vv' + str(i))\n",
    "\n",
    "vh_nbr_list = []\n",
    "for i in range(1, 25):\n",
    "    vh_nbr_list.append('vh' + str(i))\n",
    "\n",
    "print(vh_nbr_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b2bddf-1051-4bc2-be62-7b6bbb002f69",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### ESA WorldCover data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbcb1fe-b19a-4b08-a62d-a293d5c11e13",
   "metadata": {},
   "source": [
    "now we create features from land cover data. specifically, we calculate proportion of land cover within each coarse resolution pixel and use that as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f708d62d-8f1c-4a71-9216-685f503f1293",
   "metadata": {},
   "outputs": [],
   "source": [
    "lulc_data = gdal.Open('data/esa_lulc_10.tif')\n",
    "tmp_data_lulc_up = gdal.Translate('/vsimem/validation_data/saving_mask_image_100.tif', lulc_data, projWin=[ulx, uly, lrx, lry],\n",
    "                              outputType=gdalconst.GDT_Float32, noData=np.nan)\n",
    "lulc_arr_n = tmp_data_lulc_up.ReadAsArray()\n",
    "print(lulc_arr_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03bbc21-986a-4a43-adc2-b022775b02af",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(14, 12), dpi=300)\n",
    "plt.imshow(lulc_arr_n)\n",
    "plt.colorbar(orientation='horizontal')\n",
    "plt.title('LULC image over Zuid-Holland (100 m)', y=-0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e71d14-9a9f-4cbe-b965-12b4a44d5ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the window size\n",
    "window_size = [(100, 100), (10, 10)]\n",
    "lcprop_list = []\n",
    "idx_list = []\n",
    "\n",
    "# Get the image shape\n",
    "rows, cols = lulc_arr_n.shape\n",
    "\n",
    "for window_size in window_size:\n",
    "    # Compute the number of windows that fit the image\n",
    "    n_rows = int(np.ceil(rows / window_size[0]))\n",
    "    n_cols = int(np.ceil(cols / window_size[1]))\n",
    "    print(n_rows, n_cols)\n",
    "\n",
    "    # Initialize a list to store the windows\n",
    "    windows = []\n",
    "\n",
    "    # Iterate over the rows and columns of the image\n",
    "    for i in range(n_rows):\n",
    "        for j in range(n_cols):\n",
    "            # Get the starting and ending rows and columns of the window\n",
    "            start_row = i * window_size[0]\n",
    "            end_row = start_row + window_size[0]\n",
    "            start_col = j * window_size[1]\n",
    "            end_col = start_col + window_size[1]\n",
    "\n",
    "            # Get the window from the image\n",
    "            window = lulc_arr_n[start_row:end_row, start_col:end_col]\n",
    "\n",
    "            # Append the window to the list\n",
    "            windows.append(window)\n",
    "\n",
    "    # Convert the list to a numpy array\n",
    "    windows = np.array(windows)\n",
    "    # print(windows[0:10])\n",
    "\n",
    "    pixel_number_list = []\n",
    "    values_list = []\n",
    "    column_arr = np.unique(lulc_arr_n)\n",
    "\n",
    "    for array_number in range(len(windows)):\n",
    "        pixel_number_list.append(array_number)\n",
    "        unique, counts = np.unique(windows[array_number], return_counts=True)\n",
    "\n",
    "        bool_arr = np.in1d(column_arr, unique)\n",
    "\n",
    "        value_list = []\n",
    "        unique_elem_pos = 0\n",
    "        for element_pos in range(len(bool_arr)):\n",
    "            if bool_arr[element_pos] == True:\n",
    "                value = counts[unique_elem_pos]/(window_size[0]*window_size[1])\n",
    "                value_list.append(value)\n",
    "                unique_elem_pos += 1\n",
    "            else:\n",
    "                value = np.nan\n",
    "                value_list.append(value)\n",
    "\n",
    "        values_list.append(value_list)\n",
    "\n",
    "    lcprop_list.append(values_list)\n",
    "    idx_list.append(pixel_number_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d710469-e0c6-417e-9f1a-88735c649346",
   "metadata": {},
   "source": [
    "here, the lcprop_list contains two elements corresponding to the land cover proportion features of each land cover class. The first element is calculated for 1000 m resolution which will be used for training and the second element is calculated for 100 m resolution which will be used as input for the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e498d8-d23f-44f0-acab-838609c72554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to dataframe\n",
    "\n",
    "lulc_df_1000 = pd.DataFrame(data=lcprop_list[0], index=idx_list[0], columns=column_arr.tolist())\n",
    "lulc_df_1000 = lulc_df_1000.fillna(0)\n",
    "lulc_df_1000 = lulc_df_1000.drop([np.nan], axis=1)\n",
    "lulc_df_1000.columns = ['esa_0', 'esa_10', 'esa_20', 'esa_30', 'esa_40', 'esa_50', 'esa_60', 'esa_80', 'esa_90']\n",
    "lulc_df_1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634d1a3e-5e95-44de-8590-a948ee4bdc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lulc_df_1000 = lulc_df_1000.drop(['esa_0'], axis=1)\n",
    "lulc_df_1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba380f8-7461-40de-8113-9a6692e7998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to dataframe\n",
    "\n",
    "lulc_df_100 = pd.DataFrame(data=lcprop_list[1], index=idx_list[1], columns=column_arr.tolist())\n",
    "lulc_df_100 = lulc_df_100.fillna(0)\n",
    "lulc_df_100 = lulc_df_100.drop([np.nan], axis=1)\n",
    "lulc_df_100.columns = ['esa_0', 'esa_10', 'esa_20', 'esa_30', 'esa_40', 'esa_50', 'esa_60', 'esa_80', 'esa_90']\n",
    "lulc_df_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff498cda-4ee1-4036-a26e-ebe5601504d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lulc_df_100 = lulc_df_100.drop(['esa_0'], axis=1)\n",
    "lulc_df_100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260e830a-eaf4-44b6-9cdd-681791f702e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Sentinel-2 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e392a04-892f-48cb-b8cc-02ef66fb7d07",
   "metadata": {},
   "source": [
    "for sentinel-2 data we don't have any extra feature engineering. Simply, we use 1000 m data for training and 100 m data for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473da1c8-990f-4df1-be21-2105735d50fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s2 1000 m product\n",
    "\n",
    "s2_arrs = []\n",
    "\n",
    "s2_data = gdal.Open('data/s2/s2_2603_1000.tif')\n",
    "\n",
    "for i in range(s2_data.RasterCount):\n",
    "    s2_arrs.append(s2_data.ReadAsArray()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa551ed2-14f0-4eea-8354-f5855918f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten arrays to save to dataframe\n",
    "\n",
    "s2_flatten_arrs = []\n",
    "for arr in s2_arrs:\n",
    "    s2_flatten_arrs.append(arr.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9465bd4f-155b-4a03-9ec9-02db13f2c553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s2 10 m product\n",
    "\n",
    "s2_full_arrs = []\n",
    "\n",
    "s2_full = gdal.Open('data/s2/s2_2603_10.tif')\n",
    "tmp_data_s2 = gdal.Translate('/vsimem/in_memory_output.tif', s2_full, projWin=[ulx, uly, lrx, lry],\n",
    "                              outputType=gdalconst.GDT_Float32, noData=np.nan)\n",
    "\n",
    "for i in range(tmp_data_s2.RasterCount):\n",
    "    arr = ndimage.median_filter(tmp_data_s2.ReadAsArray()[i], 3)\n",
    "    s2_full_arrs.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8abc84-9978-4e79-b143-a3cf7a87217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upscale to 100 m res\n",
    "s2_full_arrs_100 = []\n",
    "\n",
    "for arr in s2_full_arrs:\n",
    "    n_arr = arr.reshape(-1, 10, 1310, 10)\n",
    "    m_n_arr = np.median(n_arr, (-1, -3))\n",
    "    s2_full_arrs_100.append(m_n_arr.flatten().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedd2500-3be7-428e-a8a0-67611f5ecf61",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### save to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbc253b-36cf-4884-a133-12916acfdf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the array to save it as a pandas dataframe\n",
    "\n",
    "lst_flat = lst_arr.flatten()\n",
    "\n",
    "vv_flat = vv_arr.flatten()\n",
    "\n",
    "vh_flat = vh_arr.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6d044f-9dea-4fdd-9934-34ed6c37d0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(lst_flat.T, columns=['lst'])\n",
    "data_df['vv'] = vv_flat.T\n",
    "data_df['vh'] = vh_flat.T\n",
    "data_df[vv_nbr_list] = np.concatenate(fnborlist_sar_1000[0])\n",
    "data_df[vh_nbr_list] = np.concatenate(fnborlist_sar_1000[1])\n",
    "\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b979a13f-7198-4379-871a-01a5f506930f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join land cover proportion df to main df\n",
    "data_df = data_df.join(lulc_df_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2030a6bd-c810-42ba-879c-77f382cd6f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save s2 to dataframe\n",
    "\n",
    "s2_cols = ['b2', 'b3', 'b4', 'b8', 'b11', 'b12']\n",
    "\n",
    "for i, col in enumerate(s2_cols):\n",
    "    data_df[col] = s2_flatten_arrs[i].T\n",
    "\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb425e0f-993b-4685-b609-534e5b05365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop entries (rows) containing NaN data\n",
    "\n",
    "filt_df = data_df.dropna()\n",
    "filt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12cdb2d-58ef-4bc3-a21a-7a63fa0730ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_list = ['vv', 'vh']\n",
    "print(predictor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b52d806-4ccf-48b1-aff9-b080a6575581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate dataframe into predictors and target for model-building\n",
    "\n",
    "predictors = filt_df[predictor_list]\n",
    "target = filt_df['lst']\n",
    "\n",
    "print(predictors)\n",
    "print()\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051bd51b-f12b-49a8-a262-6305fba54b5d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd96bf45-f2c2-44fa-b15e-4dbf495f07cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(predictors, target,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fb1d52-5633-4c50-85ac-86ef1511f52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check what pixels are selected for training, testing and validation\n",
    "\n",
    "train = y_train.isin(data_df['lst']).astype('int')\n",
    "test = y_test.isin(data_df['lst']).astype('int')\n",
    "\n",
    "data_df['test'] = test\n",
    "data_df['train'] = train\n",
    "\n",
    "train_px = data_df.train.values\n",
    "train_px = train_px.reshape(-1, 131)\n",
    "\n",
    "test_px = data_df.test.values\n",
    "test_px = test_px.reshape(-1, 131)\n",
    "\n",
    "figure(figsize=(20, 20), dpi=300)\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(train_px, cmap='Greys_r')\n",
    "plt.title('Training Set')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(test_px, cmap='Greys_r')\n",
    "plt.title('Testing Set')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8381107a-5b25-4856-998c-15a8dc735e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a grid with values for hyperparameters\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start=50, stop=2000, num=20)]\n",
    "max_depth = [int(x) for x in np.linspace(5, 30, num=10)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = np.random.randint(low=2, high=20, size=10)\n",
    "min_samples_leaf = np.random.randint(low=1, high=10, size=10)\n",
    "max_features = ['sqrt', 'log2', None]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'max_features': max_features}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab7dd73-4059-45a5-b0df-63dbc37a457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor()\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator=forest,\n",
    "                               param_distributions=random_grid,\n",
    "                               n_iter=10,\n",
    "                               cv=5, scoring='neg_root_mean_squared_error',\n",
    "                               return_train_score=True,\n",
    "                               random_state=5,\n",
    "                               n_jobs=-1)\n",
    "\n",
    "rf_random.fit(predictors, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3a16ca-26d3-462d-b32e-f864b0940fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b95991-32f7-4cbf-87a3-7f68e118d11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_forest = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce90b5bc-38da-4531-a348-75bac3fed1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_pred = tuned_forest.predict(predictors)\n",
    "full_rmse = np.sqrt(mean_squared_error(lst_pred, target))\n",
    "print(full_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a633d1-6bf1-4bcb-96cc-a4128f3e0146",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfilt_df = filt_df.copy()\n",
    "gfilt_df['lst_pred'] = lst_pred\n",
    "gfilt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee831969-1325-4a0a-aebc-ba394d3d7bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gfilt_df['lst_pred'].describe())\n",
    "print()\n",
    "print(gfilt_df['lst'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceffc4a-d6bd-4de9-a676-43f4ef6454b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfilt_df = gfilt_df['lst_pred']\n",
    "finaldata_df = data_df.join(gfilt_df)\n",
    "finaldata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2617cbae-a3dc-438b-9170-3d93a3bd15bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check model prediction at 1000 m vs original data at 1000 m\n",
    "\n",
    "hist_df_1000 = finaldata_df[['lst', 'lst_pred']]\n",
    "\n",
    "figure(figsize=(14, 12), dpi=300)\n",
    "hist_plot = hist_df_1000.plot.hist(bins=200, legend=True, alpha=0.5)\n",
    "fig = hist_plot.get_figure()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fa2854-9fa0-4a16-ad7b-c12ade8e09b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(finaldata_df['lst'].corr(finaldata_df['lst_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a693a65-6bb4-454d-886e-f62eccb7dae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_arr = finaldata_df['lst_pred'].values.reshape(-1, 131)\n",
    "print(pred_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c51f21a-fabc-4057-9662-b834dab5327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots of predicted vs observed lst at 1000 m\n",
    "\n",
    "figure(figsize=(14, 12), dpi=300)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Predicted LST map')\n",
    "plt.imshow(pred_arr[:, :], cmap='RdBu_r')\n",
    "plt.colorbar(orientation='horizontal')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Observed LST map')\n",
    "plt.imshow(lst_arr[:, :], cmap='RdBu_r')\n",
    "plt.colorbar(orientation='horizontal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccd77ee-6d7d-433d-860a-092bb11cf8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# error image at 1000 m\n",
    "\n",
    "error_arr = np.sqrt(np.square(pred_arr - lst_arr))\n",
    "\n",
    "figure(figsize=(14, 12), dpi=150)\n",
    "plt.title('Error at each pixel')\n",
    "plt.imshow(error_arr, cmap='RdYlGn_r')\n",
    "plt.colorbar(orientation='horizontal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac187d8-815c-423d-bde6-a2b2a12630ba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## downscaling 100 m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f9d8c3-fbca-4868-b7f0-c09a91eef059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the features as a dataframe\n",
    "\n",
    "lstfull_flat = lst_full_farr.flatten()\n",
    "vvfull_flat = m_vv_full_arr.flatten()\n",
    "vhfull_flat = m_vh_full_arr.flatten()\n",
    "\n",
    "fulldata_df = pd.DataFrame(lstfull_flat.T, columns=['lst'])\n",
    "fulldata_df['vv'] = vvfull_flat.T\n",
    "fulldata_df['vh'] = vhfull_flat.T\n",
    "fulldata_df[vv_nbr_list] = np.concatenate(fnborlist_sar_100[0])\n",
    "fulldata_df[vh_nbr_list] = np.concatenate(fnborlist_sar_100[1])\n",
    "\n",
    "fulldata_df = fulldata_df.join(lulc_df_100)\n",
    "fulldata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809be95c-4fb9-4138-a09f-331adc7b45cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save s2 data to dataframe\n",
    "\n",
    "for i, col in enumerate(s2_cols):\n",
    "    fulldata_df[col] = s2_full_arrs_100[i]\n",
    "\n",
    "fulldata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32b164f-3cd0-4431-8353-551e5f9f8d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_fulldata_df = fulldata_df.dropna()\n",
    "filt_fulldata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424fb964-6a7a-4551-b556-d2a0c92d115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullsar = filt_fulldata_df[predictor_list]\n",
    "fulllst = filt_fulldata_df['lst']\n",
    "\n",
    "print(fullsar)\n",
    "print(fulllst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde6a4be-1903-45e7-82ef-5613cac27edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulllst_pred = tuned_forest.predict(fullsar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348fbb90-6362-4e5e-b4b2-db804175a94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfilt_fulldata_df = filt_fulldata_df.copy()\n",
    "gfilt_fulldata_df['lst_pred'] = fulllst_pred\n",
    "gfilt_fulldata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a99c11-729f-4077-964a-d68cf8b3c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfilt_fulldata_df = gfilt_fulldata_df['lst_pred']\n",
    "n_fulldata_df = fulldata_df.join(gfilt_fulldata_df)\n",
    "n_fulldata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4128a556-6217-4aa5-95bb-2e0323138114",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## residual correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1a5162-8100-4ce3-9d3b-1e77c251c903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect residuals\n",
    "\n",
    "tmp_dlst_arr_100 = n_fulldata_df.lst_pred.values.reshape(-1, 1310)\n",
    "\n",
    "fulllst_pred_1000 = tmp_dlst_arr_100.reshape(-1, 10, 131, 10)\n",
    "fulllst_pred_1000 = np.median(fulllst_pred_1000, (-1, -3))\n",
    "print(fulllst_pred_1000.shape)\n",
    "\n",
    "# residuals\n",
    "\n",
    "res_1000 = lst_arr - fulllst_pred_1000\n",
    "print(res_1000.shape)\n",
    "\n",
    "res_100 = res_1000.repeat(10, 0).repeat(10, 1)\n",
    "print(res_100.shape)\n",
    "print(res_100)\n",
    "\n",
    "plt.imshow(res_1000)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d277b8-7b68-4005-9742-f5adf8849246",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fulldata_df['residuals'] = res_100.flatten().T\n",
    "n_fulldata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434ac65e-82ed-4d17-a2e2-634c3405c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fulldata_df['lst_pred_res'] = n_fulldata_df['lst_pred'] + n_fulldata_df['residuals']\n",
    "n_fulldata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dd71f0-7b34-480f-8164-4ee78a1fc006",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## some basic evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92c7034-a8bb-4704-888c-ca46de279887",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulllstpred_arr = n_fulldata_df.lst_pred_res.values.reshape(-1, 1310)\n",
    "reflstpred_arr = n_fulldata_df.lst.values.reshape(-1, 1310)\n",
    "\n",
    "min_min = np.nanmin(fulllstpred_arr)\n",
    "max_max = np.nanmax(fulllstpred_arr)\n",
    "\n",
    "\n",
    "# plot downscaled LST map\n",
    "\n",
    "figure(figsize=(14, 12), dpi=150)\n",
    "plt.imshow(fulllstpred_arr, vmin=min_min, vmax=max_max, cmap='RdBu_r')\n",
    "plt.colorbar(orientation='horizontal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b01808f-4bf1-4b93-b93e-eb5032f43a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(14, 12), dpi=300)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(fulllstpred_arr, vmin=min_min, vmax=max_max, cmap='RdBu_r')\n",
    "plt.title('Downscaled LST map')\n",
    "plt.colorbar(orientation='horizontal')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(reflstpred_arr, vmin=min_min, vmax=max_max, cmap='RdBu_r')\n",
    "plt.title('Original LST map')\n",
    "plt.colorbar(orientation='horizontal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c011dcf-c9fc-4269-9fbf-44d97537b287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# error for each pixel\n",
    "\n",
    "error_full_arr = np.sqrt(np.square(fulllstpred_arr - lst_full_farr))\n",
    "\n",
    "figure(figsize=(14, 12), dpi=150)\n",
    "plt.title('Error at each pixel')\n",
    "plt.imshow(error_full_arr, cmap='RdYlGn_r')\n",
    "plt.colorbar(orientation='horizontal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236b8c29-8fa6-4ff4-936c-ffc1fa678d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation coefficient\n",
    "\n",
    "corr_data_df = n_fulldata_df[['lst', 'lst_pred', 'lst_pred_res']]\n",
    "corr_data_df = corr_data_df.dropna()\n",
    "\n",
    "print('The correlation between Observed LST and Downscaled LST at 100m is:',\n",
    "      corr_data_df['lst'].corr(corr_data_df['lst_pred_res']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9324b0f9-f95c-4d4a-997d-b5681cfad520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "\n",
    "rmse_before = ((corr_data_df.lst_pred - corr_data_df.lst) ** 2).mean() ** .5\n",
    "print('RMSE before residual correction:', rmse_before)\n",
    "\n",
    "rmse_after = ((corr_data_df.lst_pred_res - corr_data_df.lst) ** 2).mean() ** .5\n",
    "print('RMSE after residual correction:', rmse_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c9d91a-df08-40c2-afcb-7ae84e609528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2 and scatterplot\n",
    "print(predictor_list)\n",
    "\n",
    "# calculate regression line using scipy.stats.linregress\n",
    "slope, intercept, r_value, p_value, std_err = linregress(corr_data_df['lst'], corr_data_df['lst_pred_res'])\n",
    "regress_line = slope * corr_data_df['lst'] + intercept\n",
    "\n",
    "r_squared = r_value ** 2\n",
    "print('R^2:', r_squared)\n",
    "\n",
    "# plot scatterplot with regression line\n",
    "plt.scatter(corr_data_df['lst'], corr_data_df['lst_pred_res'], edgecolors='black', facecolors='none', linewidths=0.5)\n",
    "plt.plot(corr_data_df['lst'], regress_line, color='red')\n",
    "plt.xlabel('Reference LST')\n",
    "plt.ylabel('Downscaled LST')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4e6cba-fd1e-4513-b20c-824b2ea9fd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram plot\n",
    "hist_df = n_fulldata_df[['lst', 'lst_pred_res']]\n",
    "\n",
    "figure(figsize=(14, 12), dpi=300)\n",
    "hist_plot = hist_df.plot.hist(bins=200, legend=True, alpha=0.5)\n",
    "fig = hist_plot.get_figure()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3ba853-7587-4b23-8797-f3d5bd3f2f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data_df_full = pd.DataFrame(data=None, columns=corr_data_df.columns, index=n_fulldata_df.index)\n",
    "corr_data_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a10d2f-ef16-404b-b355-a6b01ee3c004",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data_df_full = corr_data_df_full.combine_first(corr_data_df)\n",
    "corr_data_df_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f309ef-8205-48bc-99e3-a969acc7284d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## save as tif for further evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e186d97c-410f-4c39-86ae-ef2d8c8c28ce",
   "metadata": {},
   "source": [
    "In the dataframe 'corr_data_df_full', the column 'lst' refers to original Landsat-8 LST (100 m), the column 'lst_pred' refers to downscaled LST (100 m) without residual correction, and the column 'lst_pred_res' refers to downscaled LST (100 m) with residual correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff723eba-1bdf-4b82-9f74-6a733d63ea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_tif(img_name, src_arr, mask_img):\n",
    "    mask_data = gdal.Open(mask_img)\n",
    "    driverTiff = gdal.GetDriverByName('GTiff')\n",
    "    ds = driverTiff.Create(img_name,\n",
    "                           mask_data.RasterXSize, mask_data.RasterYSize,\n",
    "                           1, gdal.GDT_Float32)\n",
    "    ds.SetGeoTransform(mask_data.GetGeoTransform())\n",
    "    ds.SetProjection(mask_data.GetProjection())\n",
    "    ds.GetRasterBand(1).SetNoDataValue(-9999.0)\n",
    "    ds.GetRasterBand(1).WriteArray(src_arr)\n",
    "    ds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed0dd6d-3e53-4bf4-b113-22158909bf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlst_arr = corr_data_df_full.lst_pred.values.reshape(-1, 1310)\n",
    "dlst_arr_res = corr_data_df_full.lst_pred_res.values.reshape(-1, 1310)\n",
    "l8 = corr_data_df_full.lst.values.reshape(-1, 1310)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6580515f-65a5-4180-8c36-0b91461ec8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_as_tif('dlst_res_2503.tif', dlst_arr_res, 'data/saving_mask_100.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfea0d0-40b7-485c-a668-8df596bcf13e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
